print("TOKENISER\n");
load_string_table(strings_dat);
load_thing_table(things_dat);
init_tokeniser();

var old_filename_string_id: uint16 := 0;
var old_line_number: int16 := 0;
var tokens_fd: int8 := file_openout(tokens_dat);
var tokens_count: uint16 := 0;

sub write_token(token: int16)
    tokens_count := tokens_count + 1;
    file_putblock(tokens_fd, &token as [int8], 2);
end sub;

while current_token != 0 loop
    if old_filename_string_id != current_filename_string_id then
        var filename_token_id: uint16 := add_string_thing(current_filename_string_id);
        write_token(TOKEN_FILENAME);
        write_token(filename_token_id as int16);
        old_filename_string_id := current_filename_string_id;
    end if;

    if old_line_number != current_line_number then
        write_token(TOKEN_LINENUMBER);
        write_token(current_line_number);
        old_line_number := current_line_number;
    end if;

    write_token(current_token as int16);
    next_token();
end loop;

print("tokens read: ");
print_i16(tokens_count);
print_newline();
file_close(tokens_fd);

save_string_table(strings_dat);
save_thing_table(things_dat);
